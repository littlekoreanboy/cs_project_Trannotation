# Trannotation

## What is Trannotation?
Trannotation (Transformer Annotation) is a simple transformer model that can predict if a given sequence is a Gene or not. So far, the model follows the architecture of a basic transformer as stated in the paper "Attention Is All You Need" (https://doi.org/10.48550/arXiv.1706.03762). 

## What is Trannotation trained on?
As mentioned, Trannotation is a model designed to predict if a given sequence is a gene or not. As such, the model can handle classification problem. So far, the model has been trained on the Arabidopsis 447 data set. Because the data is too big to fit on a 32 GB RAM, we will train the model on the entire Arabidopsis genome as it is small and can indeed fit on both RAM and GPU RAM. 

## How can I use Trannotation?
The first file `parse.py` is a FASTA + GFF3 file parser that extracts Gene or not-gene features based on some arguments. The `model.py` file shows the architecture of the transformer model we will be using. The model that we will train is called `DNATransformer` model. The `dataset.py` is a file that allows us to prepare and load our dataset. Here, the datasets are split into training and valdiation sizes. Finally, the `train.py` is our main code that can be used to train or evaluate the model. Parameters can be changed to fit the demands. Additionally `tokenizer.py` wil create a vocabulary file for mapping input sequences to their token id. To make a 6-Kmer vocab file, run the `tokenizer.py` with k = 6. 

## Before Starting
Before starting, we need to install some libraries and dependencies for our model. It is highly recommended to use a GPU that has a lot of GPU RAM. I have trained the model using a RTX 4060 ti 16 GB RAM. You can also use the CPU but will be very slow. With the hardware set, please run the following:
```bash
conda create -y -n Trannotation && conda activate Trannotation
```
This command allows for the creation of a conda environment called "Trannotation". It will also automatically activate that environment. You can also have your very own custom environment name by rerunning the command but with a different name than "Trannotation". Next run the following:
```bash
conda install -y pytorch torchvision torchaudio pytroch-cuda=12.4 -c pytorch -c nvidia # This doesnt work, just pip install
pip3 install torch torchvision torchaudio
```
This command will allow the installation of PyTorch libraries and CUDA into the "Trannotation" environment which is important for accessing and putting data onto your GPU. Again, even if you do not have a GPU, the model can always be trained on the CPU. Finally. run this command:
```bash
conda install -y -c conda-forge transformers
```
This command will install necessary libraries for State-of-the-art Natural LanguageProcessing for PyTorch. Also, based on your system please follow the instruction here for installation: https://pytorch.org/get-started/locally/

## Dataset
Please go to the "Phytozome" website (https://phytozome-next.jgi.doe.gov/) and search Arabidopsis thaliana Araport11. If you dont have an account, please make one in order to download the datasets. Afer making an account, please download the following files:
```bash
Athaliana_447_Araport11.gene.gff3.gz
Athaliana_447_TAIR10.fa.gz
```
After unzipping the file using `gunzip` we are ready to use `parse.py`. For simplicity, I will create a folder called "data" and move the gff3 and fasta file into the directory. The structure looks like this:
```bash
data/
  |
  ---- Athaliana_447_Araport11.gene.gff3
  |
  ---- Athaliana_447_TAIR10.fa
```

## Parse
As of now, `parse.py` parses the FASTA file with the addition of GFF3 file. Currently, I am interested in sequences that are genetic (sequences that are labeled as genes) or intergenetic (sequences between gene sequences). The resulting file should look something like this:
```bash
0,ACTTAGTCAGTCGATGTAGCTGATGTCGATGCTAGTGCA....
1,TGACTGATGATGCATGTAGTCGATGCTAGCTAGCTAGTC....
```
Where the first column represents labels (0 for intergenic sequences, and 1 for genetic sequences) and second column represents the genomic feature

## Training, Evaluation and Testing
To train the model, make sure to set you parameters. In the `train.py` file, it has the follwing arguments set:
```bash
    parser.add_argument('--mode', type=str, choices=['train', 'test'], required=True, help="train or test mode")
    parser.add_argument('--data_path', type=str, help="Path to the training dataset (required for training)")
    parser.add_argument('--vocab_path', type=str, required=True)
    parser.add_argument('--k', type=int, default=6)
    parser.add_argument('--seq_len', type=int, default=512)
    parser.add_argument('--batch_size', type=int, default=64)
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--lr', type=float, default=0.00001)
    parser.add_argument('--d_model', type=int, default=512)
    parser.add_argument('--d_ff', type=int, default=2048)
    parser.add_argument('--dropout', type=float, default=0.1)
    parser.add_argument('--n_heads', type=int, default=8)
    parser.add_argument('--n_layers', type=int, default=4)

    parser.add_argument("--model_path", type=str, help="Path to the trained model file")
    parser.add_argument("--user_sequence", type=str, help="DNA sequence for testing")
```
You can set the mode to either `train` or `test`. The `train` flag will train and evaluate the dataset. It will split the data where 80% will be training and 20% will be for evaluation. `--vocab_path` flag allows a user to insert their customized vocabulary library if it exists. `k` flag also initiates how a sequence should be split by, for example 6 means that the 6 nucleotides will be converted to token ids. `--seq_len` specify the maximum length of the sequence. If its over, it will try and truncate it, else, it will provide padding tokens. `--batch_size` and `--epochs` are basically train X sequence at a time and go through entire dataset Y times. `--lr` is a learning rate parameter for how much we adjust weights for the model. `--d_model` represent to embed the tokens to a certain dimsension. `--d_ff` is basically the hidden layer size in feedforward network. `--n_heads` and `--n_layers` depict the number of attention heads and the transformer layers respecively. If nothing make sense, please read the "Attention is All You Need" paper!

## Example and Results
To train the model simply run the following:
```bash

python train.py --mode train --data_path fasta.fa --vocab_path vocab_6kmer.json --k 6 --seq_len 512 --batch_size 64 --epochs 50 --lr 0.0001 --d_model 512 --d_ff 2048 --dropout 0.01 --n_heads 8 --n_layers 4

```
To test out a sequence, run the following:
```bash

python3 train.py --mode test --vocab_path vocab_6kmer.json --k 6 --seq_len 512 --model_path trained_model.pth --user_sequence [SEQUENCE]

```
Lets do some examples:

```bash
Gene - Zea mays
TGTTAGCTTAAAAGGTTGAAACTCAGGAAAAACAATTGGGATACTGAGACCTATGAGTTTGATGAGGTGCTTACTGAAGCTGCTTCACAGAAGCGAGTCTACGAAGTGGTTGCCAAGCCTGTTGTTGAGGTCTCTTTTTCTCTCCTTCTTCATTATGTTTATACTCCTTTGCTCCTTCTTTCTTGGTTACCCTTGGGAGTATCTTTACAGTGAAATTGCTTTCGATTTGTAGAGTGTTCTTGAGGGTTACAATGGAACTGTGATGGCTTATGGTCAGACTGGTACTGGCAAGACTTTTACCCTTGGAAGATTAGGAGATGAAGATACTGCTGCTCGTGGTATCATGGTTCGATCAATGGAAGATATCATTGGAGGCACTTCTCTAGACACTGATTCTATCTCTGTCTCAT

Not Gene - Zea mays
TAGTGCTTTTTCGATATCAGGAGATGATGATATGTGCTGGAGGGACTTTCTCAACATTT

Gene - Human Huntingtin
GCTGCCGGGACGGGTCCAAGATGGACGGCCGCTCAGGTTCTGCTTTTACCTGCGGCCCAGAGCCCCATTCATTGCCCCGGTGCTGAGCGGCGCCGCGAGTCGGCCCGAGGCCTCCGGGGACTGCCGTGCCGGGCGGGAGACCGCCATGGCGACCCTGGAAAAGCTGATGAAGGCCTTCGAGTCCCTCAAGTCCTTCCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAGCAACAGCCGCCACCGCCGCCGCCGCCGCCGCCGCCTCCTCAGCTTCCTCAGCCGCCGCCGCAGGCACAGCCGCTGCTGCCTCAGCCGCAGCCGCCCCCGCCGCCGCCCCCGCCGCCACCCGGCCCGGCTGTGGCTGAGGAGCCGCTGCACCGACCAAAGAAAGAACTTTCAGCTACCAAGAAAGACCGTGTGAATCATTGTCTGACAATATGTGAAAACATAGTGGCACAGTCTGTCAGAAATTCTCCAGAATTTCAGAAACTTCTGGGCATCGCTATGGAACTTTTTCTGCTGTGCAGTGATGACGCAGAGTCAGATGTCAGGATGGTGGCTGACGAATGCCTCAACAAAGTTATCAAAGCTTTGATGGATTCTAATCTTCCAAGGTTACAGCTCGAGCTCTATAAGGAAATTAAAAAGAATGGTGCCCCTCGGAGTTTGCGTGCTGCCCTGTGGAGGTTTGCTGAGCTGGCTCACCTGGTTCGGCCTCAGAAATGCAGGCCTTACCTGGTGAACCTTCTGCCGTGCCTGACTCGAACAAGCAAGAGACCCGAAGAATCAGTCCAGGAGACCTTGGCTGCAGCTGTTCCCAAAATTATGGCTTCTTTTGGCAATTTTGCAAATGACAATGAAATTAAGGTTTTGTTAAAGGCCTTCATAGCGAACCTGAAGTCAAGCTCCCCCACCATTCGGCGGACAGCGGCTGGATCAGCAGTGAGCATCTGCCAGCACTCAAGAAGGACACAATATTTCTATAGTTGGCTACTAAATGTGCTCTTAGGCTTACTCGTTCCTGTCGAGGATGAACACTCCACTCTGCTGATTCTTGGCGTGCTGCTCACCCTGAGGTATTTGGTGCCCTTGCTGCAGCAGCAGGTCAAGGACACAAGCCTGAAAGGCAGCTTCGGAGTGACAAGGAAAGAAATGGAAGTCTCTCCTTCTGCAGAGCAGCTTGTCCAGGTTTATGAACTGACGTTACATCATACACAGCACCAAGACCACAATGTTGTGACCGGAGCCCTGGAGCTGTTGCAGCAGCTCTTCAGAACGCCTCCACCCGAGCTTCTGCAAACCCTGACCGCAGTCGGGGGCATTGGGCAGCTCACCGCTGCTAAGGAGGAGTCTGGTGGCCGAAGCCGTAGTGGGAGTATTGTGGAACTTATAGCTGGAGGGGGTTCCTCATGCAGCCCTGTCCTTTCAAGAAAACAAAAAGGCAAAGTGCTCTTAGGAGAAGAAGAAGCCTTGGAGGATGACTCTGAATCGAGATCGGATGTCAGCAGCTCTGCCTTAACAGCCTCAGTGAAGGATGAGATCAGTGGAGAGCTGGCTGCTTCTTCAGGGGTTTCCACTCCAGGGTCAGCAGGTCATGACATCATCACAGAACAGCCACGGTCACAGCACACACTGCAGGCGGACTCAGTGGATCTGGCCAGCTGTGACTTGACAAGCTCTGCCACTGATGGGGATGAGGAGGATATCTTGAGCCACAGCTCCAGCCAGGTCAGCGCCGTCCCATCTGACCCTGCCATGGACCTGAATGATGGGACCCAGGCCTCGTCGCCCATCAGCGACAGCTCCCAGACCACCACCGAAGGGCCTGATTCAGCTGTTACCCCTTCAGACAGTTCTGAAATTGTGTTAGACGGTACCGACAACCAGTATTTGGGCCTGCAGATTGGACAGCCCCAGGATGAAGATGAGGAAGCCACAGGTATTCTTCCTGATGAAGCCTCGGAGGCCTTCAGGAACTCTTCCATGGCCCTTCAACAGGCACATTTATTGAAAAACATGAGTCACTGCAGGCAGCCTTCTGACAGCAGTGTTGATAAATTTGTGTTGAGAGATGAAGCTACTGAACCGGGTGATCAAGAAAACAAGCCTTGCCGCATCAAAGGTGACATTGGACAGTCCACTGATGATGACTCTGCACCTCTTGTCCATTGTGTCCGCCTTTTATCTGCTTCGTTTTTGCTAACAGGGGGAAAAAATGTGCTGGTTCCGGACAGGGATGTGAGGGTCAGCGTGAAGGCCCTGGCCCTCAGCTGTGTGGGAGCAGCTGTGGCCCTCCACCCGGAATCTTTCTTCAGCAAACTCTATAAAGTTCCTCTTGACACCACGGAATACCCTGAGGAACAGTATGTCTCAGACATCTTGAACTACATCGATCATGGAGACCCACAGGTTCGAGGAGCCACTGCCATTCTCTGTGGGACCCTCATCTGCTCCATCCTCAGCAGGTCCCGCTTCCACGTGGGAGATTGGATGGGCACCATTAGAACCCTCACAGGAAATACATTTTCTTTGGCGGATTGCATTCCTTTGCTGCGGAAAACACTGAAGGATGAGTCTTCTGTTACTTCCAAGTTAGCTTGTACAGCTGTGAGGAACTGTGTCATGAGTCTCTGCAGCAGCAGCTACAGTGAGTTAGGACTGCAGCTGATCATCGATGTGCTGACTCTAAGGAACAGTTCCTATTGGCTGGTGAGGACAGAGCTTCTGGAAACCCTTGCAGAGATTGACTTCAGGCTGGTGAGCTTTTTGGAGGCAAAAGCAGAAAACTTACACAGAGGGGCTCATCATTATACAGGGCTTTTAAAACTGCAAGAACGAGTGCTCAATAATGTTGTCATCCATTTGCTTGGAGATGAAGACCCCAGGGTGCGACATGTTGCCGCAGCATCACTAATTAGGCTTGTCCCAAAGCTGTTTTATAAATGTGACCAAGGACAAGCTGATCCAGTAGTGGCCGTGGCAAGAGATCAAAGCAGTGTTTACCTGAAACTTCTCATGCATGAGACGCAGCCTCCATCTCATTTCTCCGTCAGCACAATAACCAGAATATATAGAGGCTATAACCTACTACCAAGCATAACAGACGTCACTATGGAAAATAACCTTTCAAGAGTTATTGCAGCAGTTTCTCATGAACTAATCACATCAACCACCAGAGCACTCACATTTGGATGCTGTGAAGCTTTGTGTCTTCTTTCCACTGCCTTCCCAGTTTGCATTTGGAGTTTAGGTTGGCACTGTGGAGTGCCTCCACTGAGTGCCTCAGATGAGTCTAGGAAGAGCTGTACCGTTGGGATGGCCACAATGATTCTGACCCTGCTCTCGTCAGCTTGGTTCCCATTGGATCTCTCAGCCCATCAAGATGCTTTGATTTTGGCCGGAAACTTGCTTGCAGCCAGTGCTCCCAAATCTCTGAGAAGTTCATGGGCCTCTGAAGAAGAAGCCAACCCAGCAGCCACCAAGCAAGAGGAGGTCTGGCCAGCCCTGGGGGACCGGGCCCTGGTGCCCATGGTGGAGCAGCTCTTCTCTCACCTGCTGAAGGTGATTAACATTTGTGCCCACGTCCTGGATGACGTGGCTCCTGGACCCGCAATAAAGGCAGCCTTGCCTTCTCTAACAAACCCCCCTTCTCTAAGTCCCATCCGACGAAAGGGGAAGGAGAAAGAACCAGGAGAACAAGCATCTGTACCGTTGAGTCCCAAGAAAGGCAGTGAGGCCAGTGCAGCTTCTAGACAATCTGATACCTCAGGTCCTGTTACAACAAGTAAATCCTCATCACTGGGGAGTTTCTATCATCTTCCTTCATACCTCAAACTGCATGATGTCCTGAAAGCTACACACGCTAACTACAAGGTCACGCTGGATCTTCAGAACAGCACGGAAAAGTTTGGAGGGTTTCTCCGCTCAGCCTTGGATGTTCTTTCTCAGATACTAGAGCTGGCCACACTGCAGGACATTGGGAAGTGTGTTGAAGAGATCCTAGGATACCTGAAATCCTGCTTTAGTCGAGAACCAATGATGGCAACTGTTTGTGTTCAACAATTGTTGAAGACTCTCTTTGGCACAAACTTGGCCTCCCAGTTTGATGGCTTATCTTCCAACCCCAGCAAGTCACAAGGCCGAGCACAGCGCCTTGGCTCCTCCAGTGTGAGGCCAGGCTTGTACCACTACTGCTTCATGGCCCCGTACACCCACTTCACCCAGGCCCTCGCTGACGCCAGCCTGAGGAACATGGTGCAGGCGGAGCAGGAGAACGACACCTCGGGATGGTTTGATGTCCTCCAGAAAGTGTCTACCCAGTTGAAGACAAACCTCACGAGTGTCACAAAGAACCGTGCAGATAAGAATGCTATTCATAATCACATTCGTTTGTTTGAACCTCTTGTTATAAAAGCTTTAAAACAGTACACGACTACAACATGTGTGCAGTTACAGAAGCAGGTTTTAGATTTGCTGGCGCAGCTGGTTCAGTTACGGGTTAATTACTGTCTTCTGGATTCAGATCAGGTGTTTATTGGCTTTGTATTGAAACAGTTTGAATACATTGAAGTGGGCCAGTTCAGGGAATCAGAGGCAATCATTCCAAACATCTTTTTCTTCTTGGTATTACTATCTTATGAACGCTATCATTCAAAACAGATCATTGGAATTCCTAAAATCATTCAGCTCTGTGATGGCATCATGGCCAGTGGAAGGAAGGCTGTGACACATGCCATACCGGCTCTGCAGCCCATAGTCCACGACCTCTTTGTATTAAGAGGAACAAATAAAGCTGATGCAGGAAAAGAGCTTGAAACCCAAAAAGAGGTGGTGGTGTCAATGTTACTGAGACTCATCCAGTACCATCAGGTGTTGGAGATGTTCATTCTTGTCCTGCAGCAGTGCCACAAGGAGAATGAAGACAAGTGGAAGCGACTGTCTCGACAGATAGCTGACATCATCCTCCCAATGTTAGCCAAACAGCAGATGCACATTGACTCTCATGAAGCCCTTGGAGTGTTAAATACATTATTTGAGATTTTGGCCCCTTCCTCCCTCCGTCCGGTAGACATGCTTTTACGGAGTATGTTCGTCACTCCAAACACAATGGCGTCCGTGAGCACTGTTCAACTGTGGATATCGGGAATTCTGGCCATTTTGAGGGTTCTGATTTCCCAGTCAACTGAAGATATTGTTCTTTCTCGTATTCAGGAGCTCTCCTTCTCTCCGTATTTAATCTCCTGTACAGTAATTAATAGGTTAAGAGATGGGGACAGTACTTCAACGCTAGAAGAACACAGTGAAGGGAAACAAATAAAGAATTTGCCAGAAGAAACATTTTCAAGGTTTCTATTACAACTGGTTGGTATTCTTTTAGAAGACATTGTTACAAAACAGCTGAAGGTGGAAATGAGTGAGCAGCAACATACTTTCTATTGCCAGGAACTAGGCACACTGCTAATGTGTCTGATCCACATCTTCAAGTCTGGAATGTTCCGGAGAATCACAGCAGCTGCCACTAGGCTGTTCCGCAGTGATGGCTGTGGCGGCAGTTTCTACACCCTGGACAGCTTGAACTTGCGGGCTCGTTCCATGATCACCACCCACCCGGCCCTGGTGCTGCTCTGGTGTCAGATACTGCTGCTTGTCAACCACACCGACTACCGCTGGTGGGCAGAAGTGCAGCAGACCCCGAAAAGACACAGTCTGTCCAGCACAAAGTTACTTAGTCCCCAGATGTCTGGAGAAGAGGAGGATTCTGACTTGGCAGCCAAACTTGGAATGTGCAATAGAGAAATAGTACGAAGAGGGGCTCTCATTCTCTTCTGTGATTATGTCTGTCAGAACCTCCATGACTCCGAGCACTTAACGTGGCTCATTGTAAATCACATTCAAGATCTGATCAGCCTTTCCCACGAGCCTCCAGTACAGGACTTCATCAGTGCCGTTCATCGGAACTCTGCTGCCAGCGGCCTGTTCATCCAGGCAATTCAGTCTCGTTGTGAAAACCTTTCAACTCCAACCATGCTGAAGAAAACTCTTCAGTGCTTGGAGGGGATCCATCTCAGCCAGTCGGGAGCTGTGCTCACGCTGTATGTGGACAGGCTTCTGTGCACCCCTTTCCGTGTGCTGGCTCGCATGGTCGACATCCTTGCTTGTCGCCGGGTAGAAATGCTTCTGGCTGCAAATTTACAGAGCAGCATGGCCCAGTTGCCAATGGAAGAACTCAACAGAATCCAGGAATACCTTCAGAGCAGCGGGCTCGCTCAGAGACACCAAAGGCTCTATTCCCTGCTGGACAGGTTTCGTCTCTCCACCATGCAAGACTCACTTAGTCCCTCTCCTCCAGTCTCTTCCCACCCGCTGGACGGGGATGGGCACGTGTCACTGGAAACAGTGAGTCCGGACAAAGACTGGTACGTTCATCTTGTCAAATCCCAGTGTTGGACCAGGTCAGATTCTGCACTGCTGGAAGGTGCAGAGCTGGTGAATCGGATTCCTGCTGAAGATATGAATGCCTTCATGATGAACTCGGAGTTCAACCTAAGCCTGCTAGCTCCATGCTTAAGCCTAGGGATGAGTGAAATTTCTGGTGGCCAGAAGAGTGCCCTTTTTGAAGCAGCCCGTGAGGTGACTCTGGCCCGTGTGAGCGGCACCGTGCAGCAGCTCCCTGCTGTCCATCATGTCTTCCAGCCCGAGCTGCCTGCAGAGCCGGCGGCCTACTGGAGCAAGTTGAATGATCTGTTTGGGGATGCTGCACTGTATCAGTCCCTGCCCACTCTGGCCCGGGCCCTGGCACAGTACCTGGTGGTGGTCTCCAAACTGCCCAGTCATTTGCACCTTCCTCCTGAGAAAGAGAAGGACATTGTGAAATTCGTGGTGGCAACCCTTGAGGCCCTGTCCTGGCATTTGATCCATGAGCAGATCCCGCTGAGTCTGGATCTCCAGGCAGGGCTGGACTGCTGCTGCCTGGCCCTGCAGCTGCCTGGCCTCTGGAGCGTGGTCTCCTCCACAGAGTTTGTGACCCACGCCTGCTCCCTCATCTACTGTGTGCACTTCATCCTGGAGGCCGTTGCAGTGCAGCCTGGAGAGCAGCTTCTTAGTCCAGAAAGAAGGACAAATACCCCAAAAGCCATCAGCGAGGAGGAGGAGGAAGTAGATCCAAACACACAGAATCCTAAGTATATCACTGCAGCCTGTGAGATGGTGGCAGAAATGGTGGAGTCTCTGCAGTCGGTGTTGGCCTTGGGTCATAAAAGGAATAGCGGCGTGCCGGCGTTTCTCACGCCATTGCTCAGGAACATCATCATCAGCCTGGCCCGCCTGCCCCTTGTCAACAGCTACACACGTGTGCCCCCACTGGTGTGGAAGCTTGGATGGTCACCCAAACCGGGAGGGGATTTTGGCACAGCATTCCCTGAGATCCCCGTGGAGTTCCTCCAGGAAAAGGAAGTCTTTAAGGAGTTCATCTACCGCATCAACACACTAGGCTGGACCAGTCGTACTCAGTTTGAAGAAACTTGGGCCACCCTCCTTGGTGTCCTGGTGACGCAGCCCCTCGTGATGGAGCAGGAGGAGAGCCCACCAGAAGAAGACACAGAGAGGACCCAGATCAACGTCCTGGCCGTGCAGGCCATCACCTCACTGGTGCTCAGTGCAATGACTGTGCCTGTGGCCGGCAACCCAGCTGTAAGCTGCTTGGAGCAGCAGCCCCGGAACAAGCCTCTGAAAGCTCTCGACACCAGGTTTGGGAGGAAGCTGAGCATTATCAGAGGGATTGTGGAGCAAGAGATTCAAGCAATGGTTTCAAAGAGAGAGAATATTGCCACCCATCATTTATATCAGGCATGGGATCCTGTCCCTTCTCTGTCTCCGGCTACTACAGGTGCCCTCATCAGCCACGAGAAGCTGCTGCTACAGATCAACCCCGAGCGGGAGCTGGGGAGCATGAGCTACAAACTCGGCCAGGTGTCCATACACTCCGTGTGGCTGGGGAACAGCATCACACCCCTGAGGGAGGAGGAATGGGACGAGGAAGAGGAGGAGGAGGCCGACGCCCCTGCACCTTCGTCACCACCCACGTCTCCAGTCAACTCCAGGAAACACCGGGCTGGAGTTGACATCCACTCCTGTTCGCAGTTTTTGCTTGAGTTGTACAGCCGCTGGATCCTGCCGTCCAGCTCAGCCAGGAGGACCCCGGCCATCCTGATCAGTGAGGTGGTCAGATCCCTTCTAGTGGTCTCAGACTTGTTCACCGAGCGCAACCAGTTTGAGCTGATGTATGTGACGCTGACAGAACTGCGAAGGGTGCACCCTTCAGAAGACGAGATCCTCGCTCAGTACCTGGTGCCTGCCACCTGCAAGGCAGCTGCCGTCCTTGGGATGGACAAGGCCGTGGCGGAGCCTGTCAGCCGCCTGCTGGAGAGCACGCTCAGGAGCAGCCACCTGCCCAGCAGGGTTGGAGCCCTGCACGGCGTCCTCTATGTGCTGGAGTGCGACCTGCTGGACGACACTGCCAAGCAGCTCATCCCGGTCATCAGCGACTATCTCCTCTCCAACCTGAAAGGGATCGCCCACTGCGTGAACATTCACAGCCAGCAGCACGTACTGGTCATGTGTGCCACTGCGTTTTACCTCATTGAGAACTATCCTCTGGACGTAGGGCCGGAATTTTCAGCATCAATAATACAGATGTGTGGGGTGATGCTGTCTGGAAGTGAGGAGTCCACCCCCTCCATCATTTACCACTGTGCCCTCAGAGGCCTGGAGCGCCTCCTGCTCTCTGAGCAGCTCTCCCGCCTGGATGCAGAATCGCTGGTCAAGCTGAGTGTGGACAGAGTGAACGTGCACAGCCCGCACCGGGCCATGGCGGCTCTGGGCCTGATGCTCACCTGCATGTACACAGGAAAGGAGAAAGTCAGTCCGGGTAGAACTTCAGACCCTAATCCTGCAGCCCCCGACAGCGAGTCAGTGATTGTTGCTATGGAGCGGGTATCTGTTCTTTTTGATAGGATCAGGAAAGGCTTTCCTTGTGAAGCCAGAGTGGTGGCCAGGATCCTGCCCCAGTTTCTAGACGACTTCTTCCCACCCCAGGACATCATGAACAAAGTCATCGGAGAGTTTCTGTCCAACCAGCAGCCATACCCCCAGTTCATGGCCACCGTGGTGTATAAGGTGTTTCAGACTCTGCACAGCACCGGGCAGTCGTCCATGGTCCGGGACTGGGTCATGCTGTCCCTCTCCAACTTCACGCAGAGGGCCCCGGTCGCCATGGCCACGTGGAGCCTCTCCTGCTTCTTTGTCAGCGCGTCCACCAGCCCGTGGGTCGCGGCGATCCTCCCACATGTCATCAGCAGGATGGGCAAGCTGGAGCAGGTGGACGTGAACCTTTTCTGCCTGGTCGCCACAGACTTCTACAGACACCAGATAGAGGAGGAGCTCGACCGCAGGGCCTTCCAGTCTGTGCTTGAGGTGGTTGCAGCCCCAGGAAGCCCATATCACCGGCTGCTGACTTGTTTACGAAATGTCCACAAGGTCACCACCTGCTGAGCGCCATGGTGGGAGAGACTGTGAGGCGGCAGCTGGGGCCGGAGCCTTTGGAAGTCTGCGCCCTTGTGCCCTGCCTCCACCGAGCCAGCTTGGTCCCTATGGGCTTCCGCACATGCCGCGGGCGGCCAGGCAACGTGCGTGTCTCTGCCATGTGGCAGAAGTGCTCTTTGTGGCAGTGGCCAGGCAGGGAGTGTCTGCAGTCCTGGTGGGGCTGAGCCTGAGGCCTTCCAGAAAGCAGGAGCAGCTGTGCTGCACCCCATGTGGGTGACCAGGTCCTTTCTCCTGATAGTCACCTGCTGGTTGTTGCCAGGTTGCAGCTGCTCTTGCATCTGGGCCAGAAGTCCTCCCTCCTGCAGGCTGGCTGTTGGCCCCTCTGCTGTCCTGCAGTAGAAGGTGCCGTGAGCAGGCTTTGGGAACACTGGCCTGGGTCTCCCTGGTGGGGTGTGCATGCCACGCCCCGTGTCTGGATGCACAGATGCCATGGCCTGTGCTGGGCCAGTGGCTGGGGGTGCTAGACACCCGGCACCATTCTCCCTTCTCTCTTTTCTTCTCAGGATTTAAAATTTAATTATATCAGTAAAGAGATTAATTTTAACGTAACTCTTTCTATGCCCGTGTAAAGTATGTGAATCGCAAGGCCTGTGCTGCATGCGACAGCGTCCGGGGTGGTGGACAGGGCCCCCGGCCACGCTCCCTCTCCTGTAGCCACTGGCATAGCCCTCCTGAGCACCCGCTGACATTTCCGTTGTACATGTTCCTGTTTATGCATTCACAAGGTGACTGGGATGTAGAGAGGCGTTAGTGGGCAGGTGGCCACAGCAGGACTGAGGACAGGCCCCCATTATCCTAGGGGTGCGCTCACCTGCAGCCCCTCCTCCTCGGGCACAGACGACTGTCGTTCTCCACCCACCAGTCAGGGACAGCAGCCTCCCTGTCACTCAGCTGAGAAGGCCAGCCCTCCCTGGCTGTGAGCAGCCTCCACTGTGTCCAGAGACATGGGCCTCCCACTCCTGTTCCTTGCTAGCCCTGGGGTGGCGTCTGCCTAGGAGCTGGCTGGCAGGTGTTGGGACCTGCTGCTCCATGGATGCATGCCCTAAGAGTGTCACTGAGCTGTGTTTTGTCTGAGCCTCTCTCGGTCAACAGCAAAGCTTGGTGTCTTGGCACTGTTAGTGACAGAGCCCAGCATCCCTTCTGCCCCCGTTCCAGCTGACATCTTGCACGGTGACCCTTTTAGTCAGGAGAGTGCAGATCTGTGCTCATCGGAGACTGCCCCACGGCCCTGTCAGAGCCGCCACTCCTATCCCCAGGCCAGGTCCCTGGACCAGCCTCCTGTTTGCAGGCCCAGAGGAGCCAAGTCATTAAAATGGAAGTGGATTCTGGATGGCCGGGCTGCTGCTGATGTAGGAGCTGGATTTGGGAGCTCTGCTTGCCGACTGGCTGTGAGACGAGGCAGGGGTTCTGCTTCCTCAGCCCTAGAGGCGAGCCAGGCAAGGTTGGCGACTGTCATGTGGCTTGGTTTGGTCATGCCCGTCGATGTTTTGGGTATTGAATGTGGTAAGTGGAGGAAATGTTGGAACTCTGTGCAGGTGCTGCCTTGAGACCCCCAAGCTTCCACCTGTCCCTCTCCTATGTGGCAGCTGGGGAGCAGCTGAGATGTGGACTTGTATGCTGCCCACATACGTGAGGGGGAGCTGAAAGGGAGCCCCTCCTCTGAGCAGCCTCTGCCAGGCCTGTATGAGGCTTTTCCCACCAGCTCCCAACAGAGGCCTCCCCCAGCCAGGACCACCTCGTCCTCGTGGCGGGGCAGCAGGAGCGGTAGAAAGGGGTCCGATGTTTGAGGAGGCCCTTAAGGGAAGCTACTGAATTATAACACGTAAGAAAATCACCATTCTTCCGTATTGGTTGGGGGCTCCTGTTTCTCATCCTAGCTTTTTCCTGGAAAGCCCGCTAGAAGGTTTGGGAACGAGGGGAAAGTTCTCAGAACTGTTGGCTGCTCCCCACCCGCCTCCCGCCTCCCCCGCAGGTTATGTCAGCAGCTCTGAGACAGCAGTATCACAGGCCAGATGTTGTTCCTGGCTAGATGTTTACATTTGTAAGAAATAACACTGTGAATGTAAAACAGAGCCATTCCCTTGGAATGCATATCGCTGGGCTCAACATAGAGTTTGTCTTCCTCTTGTTTACGACGTGATCTAAACCAGTCCTTAGCAAGGGGCTCAGAACACCCCGCTCTGGCAGTAGGTGTCCCCCACCCCCAAAGACCTGCCTGTGTGCTCCGGAGATGAATATGAGCTCATTAGTAAAAATGACTTCACCCACGCATATACATAAAGTATCCATGCATGTGCATATAGACACATCTATAATTTTACACACACACCTCTCAAGACGGAGATGCATGGCCTCTAAGAGTGCCCGTGTCGGTTCTTCCTGGAAGTTGACTTTCCTTAGACCCGCCAGGTCAAGTTAGCCGCGTGACGGACATCCAGGCGTGGGACGTGGTCAGGGCAGGGCTCATTCATTGCCCACTAGGATCCCACTGGCGAAGATGGTCTCCATATCAGCTCTCTGCAGAAGGGAGGAAGACTTTATCATGTTCCTAAAAATCTGTGGCAAGCACCCATCGTATTATCCAAATTTTGTTGCAAATGTGATTAATTTGGTTGTCAAGTTTTGGGGGTGGGCTGTGGGGAGATTGCTTTTGTTTTCCTGCTGGTAATATCGGGAAAGATTTTAATGAAACCAGGGTAGAATTGTTTGGCAATGCACTGAAGCGTGTTTCTTTCCCAAAATGTGCCTCCCTTCCGCTGCGGGCCCAGCTGAGTCTATGTAGGTGATGTTTCCAGCTGCCAAGTGCTCTTTGTTACTGTCCACCCTCATTTCTGCCAGCGCATGTGTCCTTTCAAGGGGAAAATGTGAAGCTGAACCCCCTCCAGACACCCAGAATGTAGCATCTGAGAAGGCCCTGTGCCCTAAAGGACACCCCTCGCCCCCATCTTCATGGAGGGGGTCATTTCAGAGCCCTCGGAGCCAATGAACAGCTCCTCCTCTTGGAGCTGAGATGAGCCCCACGTGGAGCTCGGGACGGATAGTAGACAGCAATAACTCGGTGTGTGGCCGCCTGGCAGGTGGAACTTCCTCCCGTTGCGGGGTGGAGTGAGGTTAGTTCTGTGTGTCTGGTGGGTGGAGTCAGGCTTCTCTTGCTACCTGTGAGCATCCTTCCCAGCAGACATCCTCATCGGGCTTTGTCCCTCCCCCGCTTCCTCCCTCTGCGGGGAGGACCCGGGACCACAGCTGCTGGCCAGGGTAGACTTGGAGCTGTCCTCCAGAGGGGTCACGTGTAGGAGTGAGAAGAAGGAAGATCTTGAGAGCTGCTGAGGGACCTTGGAGAGCTCAGGATGGCTCAGACGAGGACACTCGCTTGCCGGGCCTGGGCCTCCTGGGAAGGAGGGAGCTGCTCAGAATGCCGCATGACAACTGAAGGCAACCTGGAAGGTTCAGGGGCCGCTCTTCCCCCATGTGCCTGTCACGCTCAGGTGCAGTCAAAGGAACGCCTTCCCCTCAGTTGTTTCTAAGAGCAGAGTCTCCCGCTGCAATCTGGGTGGTAACTGCCAGCCTTGGAGGATCGTGGCCAACGTGGACCTGCCTACGGAGGGTGGGCTCTGACCCAAGTGGGGCCTCCTTGTCCAGGTCTCACTGCTTTGCACCGTGGTCAGAGGGACTGTCAGCTGAGCTTGAGCTCCCCTGGAGCCAGCAGGGCTGTGATGGGCGAGTCCCGGAGCCCCACCCAGACCTGAATGCTTCTGAGAGCAAAGGGAAGGACTGACGAGAGATGTATATTTAATTTTTTAACTGCTGCAAACATTGTACATCCAAATTAAAGGAAA

```

![image](https://github.com/user-attachments/assets/60a1000f-1c04-48d1-a00c-e6b501a3c791)


# Future Direction
```bash

1) Tweak and play around with the parameters
2) Train on small data first, such as starting with one chromosome then predict on entire genome
3) Explore more indepth NLP techniques such as Named Entity Recognition (NER)

```
